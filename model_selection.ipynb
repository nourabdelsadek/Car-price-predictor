{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b566cdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'model selection and evaluation'\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "train_data = pd.read_csv('processed_train_data.csv')\n",
    "test_data = pd.read_csv('processed_test_data.csv')\n",
    "\n",
    "X_train = train_data.drop('log_price', axis=1)\n",
    "y_train = train_data['log_price']\n",
    "\n",
    "X_test = test_data.drop('log_price', axis=1)\n",
    "y_test = test_data['log_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60a9a353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_r2(y_true_log, y_pred_log):\n",
    "    y_true_actual = np.exp(y_true_log)\n",
    "    y_pred_actual = np.exp(y_pred_log)\n",
    "    return r2_score(y_true_actual, y_pred_actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f14808f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R2: 0.9139\n",
      "Test R2: 0.9025\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Trial 1\n",
    "linear regression model\n",
    "'''\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train_log = model.predict(X_train)\n",
    "r2_train = get_r2(y_train, y_pred_train_log)\n",
    "\n",
    "y_pred_test_log = model.predict(X_test)\n",
    "r2_test = get_r2(y_test, y_pred_test_log)\n",
    "\n",
    "print(f\"Training R2: {r2_train:.4f}\")\n",
    "print(f\"Test R2: {r2_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db46393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training R2: 0.9139\n",
    "#Test R2: 0.9025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1d26365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R2: 0.9425\n",
      "Test R2: 0.9309\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Trial 2\n",
    "polynomial regression model with degree of 2 \n",
    "'''\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "poly_model = LinearRegression()\n",
    "poly_model.fit(X_train_poly, y_train)\n",
    "\n",
    "y_pred_train_log = poly_model.predict(X_train_poly)\n",
    "y_pred_test_log = poly_model.predict(X_test_poly)\n",
    "\n",
    "r2_train = get_r2(y_train, y_pred_train_log)\n",
    "r2_test = get_r2(y_test, y_pred_test_log)\n",
    "\n",
    "print(f\"Training R2: {r2_train:.4f}\")\n",
    "print(f\"Test R2: {r2_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f59ef45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training R2: 0.9425\n",
    "#Test R2: 0.9309"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eec4b3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'poly__degree': 2, 'ridge__alpha': 1}\n",
      "Train R2: 0.9407\n",
      "Test R2: 0.9306\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Trial 3\n",
    "Grid search on ridge regression with polynomial features\n",
    "and different alpha values\n",
    "'''\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('poly', PolynomialFeatures()),\n",
    "    ('ridge', Ridge())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'poly__degree': [1, 2],\n",
    "    'ridge__alpha': [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='r2',\n",
    "                           cv=3,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred_train_log = best_model.predict(X_train)\n",
    "y_pred_test_log = best_model.predict(X_test)\n",
    "\n",
    "r2_train = get_r2(y_train, y_pred_train_log)\n",
    "r2_test = get_r2(y_test, y_pred_test_log)\n",
    "\n",
    "print(f\"Best Params: {grid_search.best_params_}\")\n",
    "print(f\"Train R2: {r2_train:.4f}\")\n",
    "print(f\"Test R2: {r2_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b116baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best Params: {'poly__degree': 2, 'ridge__alpha': 1}\n",
    "#Train R2: 0.9407\n",
    "#Test R2: 0.9306"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc45eb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'learning_rate': 0.1, 'n_estimators': 500}\n",
      "Train R2: 0.9806\n",
      "Test R2: 0.9459\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Trial 4\n",
    "Grid search on XGBoost regression model with different n_estimators and learning_rate.\n",
    "'''\n",
    "import xgboost as xgb\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 100, 500, 1000, 2000],\n",
    "    'learning_rate': [0.1, 0.01, 0.001]\n",
    "}\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgb_model, \n",
    "                           param_grid=param_grid, \n",
    "                           scoring='r2', \n",
    "                           cv=3, \n",
    "                           n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred_train_log = best_model.predict(X_train)\n",
    "y_pred_test_log = best_model.predict(X_test)\n",
    "\n",
    "r2_train = get_r2(y_train, y_pred_train_log)\n",
    "r2_test = get_r2(y_test, y_pred_test_log)\n",
    "\n",
    "print(f\"Best Params: {grid_search.best_params_}\")\n",
    "print(f\"Train R2: {r2_train:.4f}\")\n",
    "print(f\"Test R2: {r2_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0545fedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best Params: {'learning_rate': 0.1, 'n_estimators': 500}\n",
    "#Train R2: 0.9806\n",
    "#Test R2: 0.9459"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08f3a002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'n_estimators': 1000}\n",
      "Train R2: 0.9883\n",
      "Test R2: 0.9361\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Trial 5\n",
    "Grid search on random forest regression model with different n_estimators.\n",
    "'''\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 100, 1000]\n",
    "}\n",
    "\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf_model, \n",
    "                           param_grid=param_grid, \n",
    "                           scoring='r2', \n",
    "                           cv=3, \n",
    "                           n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred_train_log = best_model.predict(X_train)\n",
    "y_pred_test_log = best_model.predict(X_test)\n",
    "\n",
    "r2_train = get_r2(y_train, y_pred_train_log)\n",
    "r2_test = get_r2(y_test, y_pred_test_log)\n",
    "\n",
    "print(f\"Best Params: {grid_search.best_params_}\")\n",
    "print(f\"Train R2: {r2_train:.4f}\")\n",
    "print(f\"Test R2: {r2_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f9430fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best Params: {'n_estimators': 1000}\n",
    "#Train R2: 0.9883\n",
    "#Test R2: 0.9361"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32bc93e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step\n",
      "Neural Network Train R2: 0.9446\n",
      "Neural Network Test R2: 0.9278\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Trial 6\n",
    "Neural Network regression model with 2 hidden layers\n",
    "'''\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "nn_model = Sequential()\n",
    "nn_model.add(Dense(64, activation='relu', input_shape=(input_dim,)))\n",
    "nn_model.add(Dense(32, activation='relu'))\n",
    "nn_model.add(Dense(1)) \n",
    "\n",
    "nn_model.compile(optimizer='adam', loss='mse')\n",
    "nn_model.fit(X_train, y_train, epochs=100, batch_size=64, verbose=0)\n",
    "\n",
    "y_pred_train_log = nn_model.predict(X_train).flatten()\n",
    "y_pred_test_log = nn_model.predict(X_test).flatten()\n",
    "\n",
    "r2_train = get_r2(y_train, y_pred_train_log)\n",
    "r2_test = get_r2(y_test, y_pred_test_log)\n",
    "\n",
    "print(f\"Neural Network Train R2: {r2_train:.4f}\")\n",
    "print(f\"Neural Network Test R2: {r2_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71227a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural Network Train R2: 0.9446\n",
    "#Neural Network Test R2: 0.9278"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92304454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBased on the tested models, the XGBoost regression model with n_estimators=500 and learning_rate=0.1 got the highest R2 score on the test data set.\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Based on the tested models, the XGBoost regression model with n_estimators=500 and learning_rate=0.1 got the highest R2 score on the test data set.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25ee318a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Train R2: 0.9806\n",
      "XGBoost Test R2: 0.9459\n",
      "XGBoost model successfully saved to best_model.pkl\n"
     ]
    }
   ],
   "source": [
    "#train the XGboost model with the best parameters and save it for deployment.\n",
    "import pickle\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', \n",
    "                             n_estimators=500, \n",
    "                             learning_rate=0.1, \n",
    "                             random_state=42)\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train_log = xgb_model.predict(X_train)\n",
    "y_pred_test_log = xgb_model.predict(X_test)\n",
    "\n",
    "r2_train = get_r2(y_train, y_pred_train_log)\n",
    "r2_test = get_r2(y_test, y_pred_test_log)\n",
    "\n",
    "print(f\"XGBoost Train R2: {r2_train:.4f}\")\n",
    "print(f\"XGBoost Test R2: {r2_test:.4f}\")\n",
    "\n",
    "model_filename = 'best_model.pkl'\n",
    "\n",
    "with open(model_filename, 'wb') as file:\n",
    "    pickle.dump(xgb_model, file)\n",
    "\n",
    "print(f\"XGBoost model successfully saved to {model_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
